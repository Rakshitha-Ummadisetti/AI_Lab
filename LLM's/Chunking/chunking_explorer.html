<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chunking Methods — AI Lab Day 2</title>
<link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,600;1,400&family=IBM+Plex+Mono:wght@400;500&family=DM+Sans:wght@300;400;500&display=swap" rel="stylesheet">
<style>
  *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

  :root {
    --paper: #f7f4ef;
    --paper-dark: #ede9e2;
    --ink: #1c1a17;
    --ink-light: #5a5650;
    --ink-faint: #9c9890;
    --rule: #d4cfc7;
    --blue: #2563a8;
    --red: #c0392b;
    --green: #2d6a4f;
    --purple: #6b3fa0;
    --amber: #b45309;
    --rose: #9f1239;
    --teal: #0e7490;
  }

  html { font-size: 16px; }

  body {
    background: var(--paper);
    color: var(--ink);
    font-family: 'DM Sans', sans-serif;
    font-weight: 400;
    line-height: 1.6;
    min-height: 100vh;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='300' height='300'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3CfeColorMatrix type='saturate' values='0'/%3E%3C/filter%3E%3Crect width='300' height='300' filter='url(%23n)' opacity='0.03'/%3E%3C/svg%3E");
  }

  .page { max-width: 900px; margin: 0 auto; padding: 56px 32px 80px; }

  .eyebrow { font-family: 'IBM Plex Mono', monospace; font-size: 11px; color: var(--ink-faint); letter-spacing: 0.08em; margin-bottom: 10px; }

  h1 { font-family: 'Lora', serif; font-size: clamp(1.9rem, 4vw, 2.8rem); font-weight: 600; line-height: 1.2; letter-spacing: -0.02em; margin-bottom: 10px; }

  .tagline { font-size: 15px; color: var(--ink-light); font-weight: 300; margin-bottom: 40px; }

  hr.rule { border: none; border-top: 1px solid var(--rule); margin: 32px 0; }

  .card { background: #fff; border: 1px solid var(--rule); border-radius: 6px; padding: 24px; margin-bottom: 28px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }

  .card-label { font-family: 'IBM Plex Mono', monospace; font-size: 10px; letter-spacing: 0.1em; text-transform: uppercase; color: var(--ink-faint); margin-bottom: 10px; display: block; }

  textarea { width: 100%; min-height: 150px; background: var(--paper); border: 1px solid var(--rule); border-radius: 4px; color: var(--ink); font-family: 'IBM Plex Mono', monospace; font-size: 12.5px; line-height: 1.75; padding: 14px 16px; resize: vertical; transition: border-color 0.15s; }
  textarea:focus { outline: none; border-color: var(--ink-light); }

  .controls { display: flex; gap: 24px; flex-wrap: wrap; margin-top: 16px; align-items: flex-end; }

  .field { display: flex; flex-direction: column; gap: 5px; }
  .field label { font-size: 12px; color: var(--ink-light); }
  .field-row { display: flex; align-items: center; gap: 10px; }

  input[type="range"] { width: 120px; accent-color: var(--ink); cursor: pointer; }

  .val { font-family: 'IBM Plex Mono', monospace; font-size: 12px; color: var(--ink); min-width: 30px; }

  .run-btn { background: var(--ink); color: var(--paper); border: none; border-radius: 5px; padding: 10px 22px; font-family: 'DM Sans', sans-serif; font-size: 14px; font-weight: 500; cursor: pointer; transition: background 0.15s, transform 0.1s; margin-top: auto; }
  .run-btn:hover { background: #2e2b26; }
  .run-btn:active { transform: translateY(1px); }

  .method-nav { display: flex; flex-wrap: wrap; gap: 6px; margin-bottom: 20px; }

  .mtab { font-size: 13px; padding: 6px 14px; border-radius: 20px; border: 1px solid var(--rule); background: #fff; color: var(--ink-light); cursor: pointer; transition: all 0.12s; white-space: nowrap; }
  .mtab:hover { border-color: var(--ink-light); color: var(--ink); }
  .mtab.active { color: #fff; font-weight: 500; border-color: transparent; }
  .mtab.active[data-m="fixed"]     { background: var(--blue); }
  .mtab.active[data-m="sentence"]  { background: var(--red); }
  .mtab.active[data-m="paragraph"] { background: var(--green); }
  .mtab.active[data-m="sliding"]   { background: var(--purple); }
  .mtab.active[data-m="semantic"]  { background: var(--amber); }
  .mtab.active[data-m="recursive"] { background: var(--rose); }
  .mtab.active[data-m="token"]     { background: var(--teal); }

  .results-bar { display: flex; justify-content: space-between; align-items: baseline; margin-bottom: 8px; flex-wrap: wrap; gap: 8px; }

  .method-heading { font-family: 'Lora', serif; font-size: 1.3rem; font-weight: 600; font-style: italic; }

  .stats-inline { font-family: 'IBM Plex Mono', monospace; font-size: 11px; color: var(--ink-faint); display: flex; gap: 16px; }
  .stats-inline span b { color: var(--ink-light); font-weight: 500; }

  .method-note { font-size: 13px; color: var(--ink-light); line-height: 1.65; margin-bottom: 20px; padding-bottom: 16px; border-bottom: 1px solid var(--rule); }

  .view-toggle { display: inline-flex; border: 1px solid var(--rule); border-radius: 5px; overflow: hidden; background: #fff; margin-bottom: 20px; }
  .vtab { font-size: 12px; padding: 6px 16px; border: none; background: transparent; color: var(--ink-light); cursor: pointer; border-right: 1px solid var(--rule); transition: all 0.12s; }
  .vtab:last-child { border-right: none; }
  .vtab.active { background: var(--ink); color: var(--paper); font-weight: 500; }

  .chunks-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(260px, 1fr)); gap: 12px; }

  .chunk-card { background: #fff; border: 1px solid var(--rule); border-radius: 5px; padding: 16px; animation: rise 0.25s ease both; transition: box-shadow 0.15s; }
  .chunk-card:hover { box-shadow: 0 2px 12px rgba(0,0,0,0.08); }

  @keyframes rise { from { opacity:0; transform:translateY(6px); } to { opacity:1; transform:translateY(0); } }

  .chunk-card[data-m="fixed"]     { border-left: 3px solid var(--blue); }
  .chunk-card[data-m="sentence"]  { border-left: 3px solid var(--red); }
  .chunk-card[data-m="paragraph"] { border-left: 3px solid var(--green); }
  .chunk-card[data-m="sliding"]   { border-left: 3px solid var(--purple); }
  .chunk-card[data-m="semantic"]  { border-left: 3px solid var(--amber); }
  .chunk-card[data-m="recursive"] { border-left: 3px solid var(--rose); }
  .chunk-card[data-m="token"]     { border-left: 3px solid var(--teal); }

  .chunk-index { font-family: 'IBM Plex Mono', monospace; font-size: 10px; letter-spacing: 0.08em; color: var(--ink-faint); margin-bottom: 8px; }
  .chunk-body { font-family: 'IBM Plex Mono', monospace; font-size: 11.5px; line-height: 1.75; color: var(--ink); word-break: break-word; white-space: pre-wrap; }
  .chunk-meta { display: flex; justify-content: space-between; margin-top: 12px; padding-top: 10px; border-top: 1px solid var(--paper-dark); font-family: 'IBM Plex Mono', monospace; font-size: 10px; color: var(--ink-faint); }

  .empty { padding: 60px 0; text-align: center; color: var(--ink-faint); font-size: 14px; font-style: italic; font-family: 'Lora', serif; }

  .compare-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 12px; }
  .compare-card { background: #fff; border: 1px solid var(--rule); border-radius: 5px; padding: 18px; }
  .compare-card h3 { font-size: 13px; font-weight: 600; margin-bottom: 12px; }
  .bar-row { margin-bottom: 10px; }
  .bar-labels { display: flex; justify-content: space-between; font-family: 'IBM Plex Mono', monospace; font-size: 10px; color: var(--ink-faint); margin-bottom: 3px; }
  .bar-track { height: 6px; background: var(--paper-dark); border-radius: 3px; overflow: hidden; }
  .bar-fill { height: 100%; border-radius: 3px; transition: width 0.5s cubic-bezier(0.4,0,0.2,1); }

  .tips-section { margin-top: 48px; padding-top: 32px; border-top: 1px solid var(--rule); }
  .tips-section h2 { font-family: 'Lora', serif; font-size: 1.1rem; font-weight: 600; margin-bottom: 4px; }
  .tips-sub { font-size: 13px; color: var(--ink-faint); margin-bottom: 20px; }
  .tips-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(220px, 1fr)); gap: 10px; }
  .tip { background: #fff; border: 1px solid var(--rule); border-radius: 5px; padding: 14px 16px; }
  .tip h4 { font-size: 13px; font-weight: 600; margin-bottom: 5px; }
  .tip p { font-size: 12px; color: var(--ink-light); line-height: 1.55; }
  .tip[data-m="fixed"]     h4 { color: var(--blue); }
  .tip[data-m="sentence"]  h4 { color: var(--red); }
  .tip[data-m="paragraph"] h4 { color: var(--green); }
  .tip[data-m="sliding"]   h4 { color: var(--purple); }
  .tip[data-m="semantic"]  h4 { color: var(--amber); }
  .tip[data-m="recursive"] h4 { color: var(--rose); }
  .tip[data-m="token"]     h4 { color: var(--teal); }

  @media (max-width: 640px) {
    .compare-grid { grid-template-columns: 1fr; }
    .page { padding: 36px 18px 60px; }
  }
</style>
</head>
<body>
<div class="page">

  <header>
    <p class="eyebrow">AI Lab · Day 2 of building</p>
    <h1>Chunking Methods</h1>
    <p class="tagline">Paste any text, adjust settings, and watch how different strategies slice it up.</p>
  </header>

  <hr class="rule">

  <div class="card">
    <span class="card-label">Source text</span>
    <textarea id="inputText">Artificial intelligence is transforming the way we interact with technology. Machine learning models can now understand and generate human language with remarkable accuracy. This has led to breakthroughs in many fields.

Natural language processing enables computers to read and understand text. It powers applications like chatbots, search engines, and translation services. The field has seen rapid growth in recent years.

Large language models like GPT and Claude are trained on vast amounts of text data. They learn patterns in language and can generate coherent responses to prompts. These models use transformer architecture, which processes text in parallel rather than sequentially.

Retrieval-Augmented Generation (RAG) combines the power of LLMs with external knowledge bases. Instead of relying solely on training data, RAG systems retrieve relevant documents and use them to generate more accurate, grounded responses. Chunking is a critical step in building effective RAG pipelines.

The choice of chunking strategy significantly impacts retrieval quality. Smaller chunks allow more precise retrieval but may lose context. Larger chunks preserve context but can introduce noise. Finding the right balance is key to building effective AI systems.</textarea>

    <div class="controls">
      <div class="field">
        <label>Chunk size (chars)</label>
        <div class="field-row">
          <input type="range" id="chunkSize" min="50" max="500" value="200" oninput="upd('sizeVal',this.value)">
          <span class="val" id="sizeVal">200</span>
        </div>
      </div>
      <div class="field">
        <label>Overlap (chars)</label>
        <div class="field-row">
          <input type="range" id="overlap" min="0" max="150" value="30" oninput="upd('overlapVal',this.value)">
          <span class="val" id="overlapVal">30</span>
        </div>
      </div>
      <button class="run-btn" onclick="runAll()">Run chunking</button>
    </div>
  </div>

  <div class="method-nav">
    <div class="mtab active" data-m="fixed"     onclick="switchTo('fixed')">Fixed size</div>
    <div class="mtab"        data-m="sentence"  onclick="switchTo('sentence')">Sentence</div>
    <div class="mtab"        data-m="paragraph" onclick="switchTo('paragraph')">Paragraph</div>
    <div class="mtab"        data-m="sliding"   onclick="switchTo('sliding')">Sliding window</div>
    <div class="mtab"        data-m="semantic"  onclick="switchTo('semantic')">Semantic</div>
    <div class="mtab"        data-m="recursive" onclick="switchTo('recursive')">Recursive</div>
    <div class="mtab"        data-m="token"     onclick="switchTo('token')">Token-based</div>
  </div>

  <div class="results-bar">
    <span class="method-heading" id="mHeading">Fixed size chunking</span>
    <div class="stats-inline">
      <span><b id="sChunks">—</b> chunks</span>
      <span><b id="sAvg">—</b> avg chars</span>
      <span><b id="sTotal">—</b> total</span>
    </div>
  </div>

  <p class="method-note" id="mNote">Adjust settings and click "Run chunking" to see results.</p>

  <div class="view-toggle">
    <button class="vtab active" onclick="setView('chunks',this)">Chunks</button>
    <button class="vtab"        onclick="setView('compare',this)">Compare all</button>
  </div>

  <div id="chunksPane">
    <div class="empty">No chunks yet — hit "Run chunking" to start.</div>
  </div>
  <div id="comparePane" style="display:none">
    <div class="compare-grid" id="compareGrid"></div>
  </div>

  <div class="tips-section">
    <h2>When to use each strategy</h2>
    <p class="tips-sub">A quick reference for picking the right approach in your RAG pipeline.</p>
    <div class="tips-grid">
      <div class="tip" data-m="fixed">
        <h4>Fixed size</h4>
        <p>Word-boundary-snapped character windows. Fast baseline. Use for homogeneous data where structure doesn't matter.</p>
      </div>
      <div class="tip" data-m="sentence">
        <h4>Sentence-based</h4>
        <p>Abbreviation-aware splitter (handles Dr., U.S., 3.5). Groups sentences to fill the size budget. Best for Q&amp;A and factual retrieval.</p>
      </div>
      <div class="tip" data-m="paragraph">
        <h4>Paragraph-based</h4>
        <p>Respects \n\n boundaries; recursively splits oversized paragraphs. Best for reports, wikis, and long-form docs.</p>
      </div>
      <div class="tip" data-m="sliding">
        <h4>Sliding window</h4>
        <p>Word-snapped overlap ensures real text continuity across boundaries. Use for narrative text or anywhere cross-boundary context matters.</p>
      </div>
      <div class="tip" data-m="semantic">
        <h4>Semantic</h4>
        <p>TF-IDF cosine similarity with adaptive σ-based breakpoints. Mirrors embedding chunking logic without an API call. Best for mixed-topic documents.</p>
      </div>
      <div class="tip" data-m="recursive">
        <h4>Recursive</h4>
        <p>Faithful LangChain implementation: separator hierarchy with piece merging. Handles code, markdown, and structured prose equally well.</p>
      </div>
      <div class="tip" data-m="token">
        <h4>Token-based</h4>
        <p>BPE-approximate token counting with sentence-level overlap carry. Much more accurate than chars÷4. Essential for production RAG near context limits.</p>
      </div>
    </div>
  </div>

</div>
<script>
const ACCENT = { fixed:'#2563a8', sentence:'#c0392b', paragraph:'#2d6a4f', sliding:'#6b3fa0', semantic:'#b45309', recursive:'#9f1239', token:'#0e7490' };
const LABELS = { fixed:'Fixed size chunking', sentence:'Sentence-based chunking', paragraph:'Paragraph-based chunking', sliding:'Sliding window chunking', semantic:'Semantic chunking', recursive:'Recursive chunking', token:'Token-based chunking' };
const NOTES  = {
  fixed:     'Splits text into equal-sized character windows, snapping to the nearest word boundary so chunks never cut mid-word. Simple and predictable — good baseline.',
  sentence:  'Uses an abbreviation-aware tokenizer that correctly handles "Dr.", "U.S.", decimals, and initials before splitting. Groups sentences until the chunk reaches the size limit.',
  paragraph: 'Splits on double newlines (\\n\\n) first, respecting author structure. If a paragraph exceeds the size limit, it\'s recursively split into sentences — no arbitrary merging.',
  sliding:   'Overlapping fixed-size windows with word-boundary snapping. Each step advances by (size − overlap) chars. Overlap is carried as real text, not a counter.',
  semantic:  'TF-IDF cosine similarity between sliding sentence windows. Computes mean/std of similarity scores and breaks where similarity drops below mean − 0.5σ — an adaptive threshold that mirrors embedding-based chunking logic.',
  recursive: 'Faithful LangChain RecursiveCharacterTextSplitter: tries \\n\\n → \\n → ". " → ", " → " " in order. Separators are kept with their chunk. Small pieces are merged up to size before splitting further.',
  token:     'BPE-approximate tokenizer: short words = 1 token, longer words split into ~4-char subwords, punctuation counted individually, digits per group. Carries overlap as trailing sentences, not a char count.'
};

let current = 'fixed', results = {}, view = 'chunks';
function upd(id, v) { document.getElementById(id).textContent = v; }

function runAll() {
  const text = document.getElementById('inputText').value.trim();
  if (!text) return;
  const sz = +document.getElementById('chunkSize').value;
  const ov = +document.getElementById('overlap').value;
  results.fixed     = fixedChunk(text, sz);
  results.sentence  = sentenceChunk(text, sz);
  results.paragraph = paragraphChunk(text, sz);
  results.sliding   = slidingChunk(text, sz, ov);
  results.semantic  = semanticChunk(text, sz);
  results.recursive = recursiveChunk(text, sz);
  results.token     = tokenChunk(text, sz, ov);
  renderCurrent();
  if (view === 'compare') renderCompare();
}

function switchTo(m) {
  current = m;
  document.querySelectorAll('.mtab').forEach(t => t.classList.toggle('active', t.dataset.m === m));
  renderCurrent();
}

function setView(v, btn) {
  view = v;
  document.querySelectorAll('.vtab').forEach(b => b.classList.remove('active'));
  btn.classList.add('active');
  document.getElementById('chunksPane').style.display  = v === 'chunks'  ? '' : 'none';
  document.getElementById('comparePane').style.display = v === 'compare' ? '' : 'none';
  if (v === 'compare') renderCompare();
}

function renderCurrent() {
  document.getElementById('mHeading').textContent = LABELS[current];
  document.getElementById('mNote').textContent = NOTES[current];
  const chunks = results[current];
  if (!chunks || !chunks.length) {
    document.getElementById('chunksPane').innerHTML = '<div class="empty">No chunks yet — hit "Run chunking" to start.</div>';
    ['sChunks','sAvg','sTotal'].forEach(id => document.getElementById(id).textContent = '—');
    return;
  }
  const total = chunks.reduce((a,c) => a+c.length, 0);
  const avg   = Math.round(total / chunks.length);
  document.getElementById('sChunks').textContent = chunks.length;
  document.getElementById('sAvg').textContent = avg;
  document.getElementById('sTotal').textContent = total;
  document.getElementById('chunksPane').innerHTML = '<div class="chunks-grid">' +
    chunks.map((c,i) => `<div class="chunk-card" data-m="${current}" style="animation-delay:${i*0.035}s">
      <div class="chunk-index">chunk ${String(i+1).padStart(2,'0')}</div>
      <div class="chunk-body">${esc(c)}</div>
      <div class="chunk-meta"><span>${c.length} chars</span><span>~${Math.round(c.length/4)} tokens</span></div>
    </div>`).join('') + '</div>';
}

function renderCompare() {
  if (!Object.keys(results).length) {
    document.getElementById('compareGrid').innerHTML = '<div style="grid-column:1/-1;font-style:italic;color:#9c9890;font-size:13px;padding:40px 0;text-align:center">Run chunking first.</div>';
    return;
  }
  const maxCount = Math.max(...Object.values(results).map(r => r.length));
  const maxAvg   = Math.max(...Object.values(results).map(r => r.length ? Math.round(r.reduce((a,c)=>a+c.length,0)/r.length) : 0));
  document.getElementById('compareGrid').innerHTML = Object.keys(LABELS).map(k => {
    const ch = results[k] || [];
    const avg = ch.length ? Math.round(ch.reduce((a,c)=>a+c.length,0)/ch.length) : 0;
    const col = ACCENT[k];
    return `<div class="compare-card">
      <h3 style="color:${col}">${LABELS[k]}</h3>
      <div class="bar-row">
        <div class="bar-labels"><span>Chunk count</span><span>${ch.length}</span></div>
        <div class="bar-track"><div class="bar-fill" style="width:${maxCount?ch.length/maxCount*100:0}%;background:${col}"></div></div>
      </div>
      <div class="bar-row">
        <div class="bar-labels"><span>Avg size</span><span>${avg} chars</span></div>
        <div class="bar-track"><div class="bar-fill" style="width:${maxAvg?avg/maxAvg*100:0}%;background:${col}88"></div></div>
      </div>
      <div style="font-family:'IBM Plex Mono',monospace;font-size:10px;color:#9c9890;margin-top:6px">~${Math.round(avg/4)} tokens avg</div>
    </div>`;
  }).join('');
}

function esc(t) { return t.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;'); }

// ─────────────────────────────────────────────
// SHARED UTILITIES
// ─────────────────────────────────────────────

// Abbreviation-aware sentence tokenizer.
// Handles: Dr. Mr. Mrs. U.S. e.g. i.e. decimals (3.14) initials (J.K.)
// Strategy: split on ". " / "! " / "? " but NOT when preceded by a known
// abbreviation or a single capital/lowercase letter (initials).
function splitSentences(text) {
  // Known title/abbreviation prefixes (lowercase for matching)
  const ABBREVS = new Set([
    'mr','mrs','ms','dr','prof','sr','jr','vs','etc','inc','ltd','corp',
    'dept','est','approx','appt','apt','ave','blvd','st','rd',
    'jan','feb','mar','apr','jun','jul','aug','sep','oct','nov','dec',
    'e.g','i.e','fig','vol','no','pp','ed','rev','repr',
  ]);

  // Step 1: protect known abbreviations and decimals with a placeholder
  // Replace "Abbrev." with "Abbrev<STOP>" so it won't be split on
  let protected_ = text;

  // Protect decimal numbers: 3.14 → 3<D>14
  protected_ = protected_.replace(/(\d+)\.(\d+)/g, '$1<D>$2');

  // Protect known abbreviations: "Dr." → "Dr<A>"
  protected_ = protected_.replace(/\b([A-Za-z]{1,5})\./g, (match, word) => {
    if (ABBREVS.has(word.toLowerCase())) return word + '<A>';
    // Single letter initials like J. K. also protect
    if (word.length === 1) return word + '<A>';
    return match; // leave as-is, may be real sentence end
  });

  // Step 2: split on sentence-ending punctuation followed by whitespace + capital
  // This catches ". T", "! T", "? T" patterns
  const raw = protected_.split(/(?<=[.!?])\s+(?=[A-Z"'])/);

  // Step 3: restore placeholders and trim
  return raw
    .map(s => s.replace(/<D>/g, '.').replace(/<A>/g, '.').trim())
    .filter(Boolean);
}

// BPE-approximate tokenizer — much more accurate than chars/4.
// Splits words into subword pieces mimicking GPT-2 BPE behavior:
//   - Common short words stay as 1 token
//   - Longer words split into ~4-char subword pieces
//   - Punctuation and whitespace are separate tokens
//   - Numbers: each digit group is a token
// Returns token count for a string.
function countTokens(text) {
  if (!text) return 0;
  let count = 0;
  // Tokenize like GPT-2: split on whitespace boundaries keeping punctuation
  const words = text.match(/\w+|[^\w\s]|\s+/g) || [];
  for (const w of words) {
    if (/^\s+$/.test(w)) {
      // Whitespace merges into next token, don't count separately
      continue;
    } else if (/^\d+$/.test(w)) {
      // Numbers: roughly 1 token per 1-3 digits
      count += Math.ceil(w.length / 2);
    } else if (/^[^\w]+$/.test(w)) {
      // Pure punctuation: usually 1 token each character
      count += w.length;
    } else {
      // Words: common short words = 1 token; longer = ceil(len/4) subwords
      if (w.length <= 4) count += 1;
      else count += Math.ceil(w.length / 4);
    }
  }
  return Math.max(1, count);
}

// Snap a character index backward to the nearest word boundary
function snapWordBack(text, idx) {
  if (idx >= text.length) return text.length;
  // Walk back until we hit whitespace
  while (idx > 0 && !/\s/.test(text[idx])) idx--;
  return idx;
}

// ─────────────────────────────────────────────
// 1. FIXED SIZE — snaps to word boundaries
// ─────────────────────────────────────────────
function fixedChunk(text, size) {
  const out = [];
  let start = 0;
  while (start < text.length) {
    let end = start + size;
    if (end < text.length) {
      // Snap back to nearest word boundary so we don't cut mid-word
      const snapped = snapWordBack(text, end);
      end = snapped > start ? snapped : start + size; // fallback if no space found
    }
    const chunk = text.slice(start, end).trim();
    if (chunk) out.push(chunk);
    start = end;
    // Skip leading whitespace for next chunk
    while (start < text.length && /\s/.test(text[start])) start++;
  }
  return out;
}

// ─────────────────────────────────────────────
// 2. SENTENCE-BASED — proper abbreviation-aware
// ─────────────────────────────────────────────
function sentenceChunk(text, size) {
  const sentences = splitSentences(text);
  if (!sentences.length) return [text];

  const out = [];
  let group = [];
  let groupLen = 0;

  for (const sent of sentences) {
    const adding = group.length ? groupLen + 1 + sent.length : sent.length;
    if (group.length > 0 && adding > size) {
      out.push(group.join(' '));
      group = [sent];
      groupLen = sent.length;
    } else {
      group.push(sent);
      groupLen = adding;
    }
  }
  if (group.length) out.push(group.join(' '));
  return out.filter(Boolean);
}

// ─────────────────────────────────────────────
// 3. PARAGRAPH-BASED — split on \n\n, recursively
//    split oversized paragraphs instead of merging
// ─────────────────────────────────────────────
function paragraphChunk(text, size) {
  const paras = text.split(/\n\n+/).map(p => p.trim()).filter(Boolean);
  const out = [];

  for (const para of paras) {
    if (para.length <= size) {
      out.push(para);
    } else {
      // Paragraph is too big — split it into sentences and regroup
      const sentences = splitSentences(para);
      let group = [], groupLen = 0;
      for (const s of sentences) {
        const adding = group.length ? groupLen + 1 + s.length : s.length;
        if (group.length > 0 && adding > size) {
          out.push(group.join(' '));
          group = [s]; groupLen = s.length;
        } else {
          group.push(s); groupLen = adding;
        }
      }
      if (group.length) out.push(group.join(' '));
    }
  }
  return out.filter(Boolean);
}

// ─────────────────────────────────────────────
// 4. SLIDING WINDOW — word-boundary-snapped overlap
// ─────────────────────────────────────────────
function slidingChunk(text, size, overlap) {
  if (overlap >= size) overlap = Math.floor(size * 0.5); // guard
  const step = size - overlap;
  const out = [];
  let start = 0;

  while (start < text.length) {
    let end = start + size;
    if (end < text.length) {
      const snapped = snapWordBack(text, end);
      end = snapped > start ? snapped : start + size;
    }
    const chunk = text.slice(start, Math.min(end, text.length)).trim();
    if (chunk) out.push(chunk);

    // Next window starts `step` chars ahead, snapped to word boundary
    let nextStart = start + step;
    // Snap forward to start of a word
    while (nextStart < text.length && /\s/.test(text[nextStart])) nextStart++;
    if (nextStart >= text.length || nextStart <= start) break;
    start = nextStart;
  }
  return out;
}

// ─────────────────────────────────────────────
// 5. SEMANTIC — real TF-IDF cosine similarity
//    (best approximation without embeddings in-browser)
//    Uses sliding-window sentence similarity + breakpoint detection
// ─────────────────────────────────────────────
function semanticChunk(text, size) {
  const sentences = splitSentences(text);
  if (sentences.length <= 1) return sentences.length ? sentences : [text];

  const STOPWORDS = new Set([
    'the','a','an','is','are','was','were','and','or','but','in','on','at',
    'to','for','of','with','by','from','it','its','this','that','these','those',
    'be','been','being','have','has','had','do','does','did','will','would',
    'could','should','may','might','can','not','no','so','as','if','then',
    'than','too','very','just','also','into','about','up','out','when','where',
    'which','who','they','their','there','we','our','you','your','he','she',
  ]);

  // Build TF vector for each sentence
  function termFreq(s) {
    const words = s.toLowerCase().replace(/[^a-z0-9 ]/g, ' ').split(/\s+/)
      .filter(w => w.length > 2 && !STOPWORDS.has(w));
    const freq = {};
    for (const w of words) freq[w] = (freq[w] || 0) + 1;
    return freq;
  }

  // Cosine similarity between two TF vectors
  function cosine(a, b) {
    let dot = 0, magA = 0, magB = 0;
    const allKeys = new Set([...Object.keys(a), ...Object.keys(b)]);
    for (const k of allKeys) {
      const va = a[k] || 0, vb = b[k] || 0;
      dot += va * vb; magA += va * va; magB += vb * vb;
    }
    if (!magA || !magB) return 0;
    return dot / (Math.sqrt(magA) * Math.sqrt(magB));
  }

  const vecs = sentences.map(termFreq);

  // Use a sliding window of 2 sentences to compute similarity between
  // consecutive sentence pairs — mirrors what embedding-based chunking does
  const sims = [];
  for (let i = 0; i < sentences.length - 1; i++) {
    // Compare window around i vs window around i+1 for more robustness
    const windowA = sentences.slice(Math.max(0,i-1), i+2).join(' ');
    const windowB = sentences.slice(i, Math.min(sentences.length, i+3)).join(' ');
    sims.push(cosine(termFreq(windowA), termFreq(windowB)));
  }

  // Compute mean and std of similarities to find breakpoints
  const mean = sims.reduce((a,v) => a+v, 0) / sims.length;
  const std  = Math.sqrt(sims.reduce((a,v) => a+(v-mean)**2, 0) / sims.length);
  // Break where similarity drops below mean - 0.5*std (adaptive threshold)
  const threshold = mean - 0.5 * std;

  const breakpoints = new Set();
  for (let i = 0; i < sims.length; i++) {
    if (sims[i] < threshold) breakpoints.add(i + 1); // break AFTER sentence i
  }

  // Group sentences into chunks; also respect max size
  const out = [];
  let group = [];
  let groupLen = 0;

  for (let i = 0; i < sentences.length; i++) {
    const s = sentences[i];
    if (group.length > 0 && (breakpoints.has(i) || groupLen + s.length > size * 1.5)) {
      out.push(group.join(' '));
      group = [s]; groupLen = s.length;
    } else {
      group.push(s); groupLen += s.length + 1;
    }
  }
  if (group.length) out.push(group.join(' '));
  return out.filter(Boolean);
}

// ─────────────────────────────────────────────
// 6. RECURSIVE — faithful LangChain implementation
//    Key fix: separators are kept with the chunk (like LangChain),
//    and merging of small pieces is done after splitting
// ─────────────────────────────────────────────
function recursiveChunk(text, size) {
  const SEPARATORS = ['\n\n', '\n', '. ', '! ', '? ', '; ', ', ', ' ', ''];

  function _split(t, sepIdx) {
    if (t.length <= size) return [t];
    if (sepIdx >= SEPARATORS.length) {
      // Last resort: hard cut at word boundary
      const chunks = [];
      let start = 0;
      while (start < t.length) {
        let end = start + size;
        if (end < t.length) {
          const snap = snapWordBack(t, end);
          end = snap > start ? snap : start + size;
        }
        chunks.push(t.slice(start, end).trim());
        start = end;
        while (start < t.length && /\s/.test(t[start])) start++;
      }
      return chunks.filter(Boolean);
    }

    const sep = SEPARATORS[sepIdx];
    // If separator not present, try next
    if (sep && !t.includes(sep)) return _split(t, sepIdx + 1);

    // Split by separator
    const pieces = sep ? t.split(sep) : t.split('');

    // Merge small pieces together up to `size`, then recursively split large ones
    const goodChunks = [];
    let current = '';

    for (let i = 0; i < pieces.length; i++) {
      const piece = pieces[i];
      if (!piece.trim()) continue;

      // Re-attach the separator to the end of each piece (except last)
      // This mirrors LangChain's keep_separator=True behavior
      const pieceWithSep = (i < pieces.length - 1 && sep) ? piece + sep : piece;
      const candidate = current ? current + pieceWithSep : pieceWithSep;

      if (candidate.length > size && current) {
        // Current accumulation is full — flush it
        if (current.length > size) {
          // Even the current piece alone is too big — recurse
          goodChunks.push(..._split(current.trim(), sepIdx + 1));
        } else {
          goodChunks.push(current.trim());
        }
        current = pieceWithSep;
      } else {
        current = candidate;
      }
    }

    if (current.trim()) {
      if (current.length > size) {
        goodChunks.push(..._split(current.trim(), sepIdx + 1));
      } else {
        goodChunks.push(current.trim());
      }
    }

    return goodChunks.filter(Boolean);
  }

  return _split(text, 0).filter(c => c.trim());
}

// ─────────────────────────────────────────────
// 7. TOKEN-BASED — BPE-approximate token counting
//    Uses countTokens() instead of chars/4
//    Splits sentence-by-sentence to stay within token budget
// ─────────────────────────────────────────────
function tokenChunk(text, size, overlap) {
  // Convert char-based size to token budget (size slider is in chars)
  // Typical ratio: 1 token ≈ 4 chars for English prose
  const tokenBudget = Math.round(size / 4);
  const overlapTokens = Math.round(overlap / 4);

  const sentences = splitSentences(text);
  if (!sentences.length) return [text];

  const out = [];
  let group = [];
  let groupTokens = 0;

  for (const sent of sentences) {
    const sentTokens = countTokens(sent);

    if (group.length > 0 && groupTokens + sentTokens > tokenBudget) {
      // Flush current group
      out.push(group.join(' '));

      // Carry over trailing sentences for overlap
      if (overlapTokens > 0) {
        let carry = [], carryTokens = 0;
        for (let i = group.length - 1; i >= 0; i--) {
          const t = countTokens(group[i]);
          if (carryTokens + t > overlapTokens) break;
          carry.unshift(group[i]);
          carryTokens += t;
        }
        group = [...carry, sent];
        groupTokens = carryTokens + sentTokens;
      } else {
        group = [sent];
        groupTokens = sentTokens;
      }
    } else {
      group.push(sent);
      groupTokens += sentTokens;
    }
  }

  if (group.length) out.push(group.join(' '));
  return out.filter(Boolean);
}

switchTo('fixed');
</script>
</body>
</html>